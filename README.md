# Detect total amount TTC on receipt document with Transforms approach

## Composition of the folder

- *cord_v2_dataset*: This is the CORD-v2 dataset split in train, validation and test set. This dataset is locally download by running the notebook **finetune_LayoutLMv3**

- *data*: This is the dataset of receipt images provided in the link https://expressexpense.com/blog/free-receipt-images-ocr-machine-learning-dataset/

- *mapping*: This folder contains the mapping dictionaries (.pkl) label2id and id2label. These elements are created by running the notebook 
**finetune_LayoutLMv3**

- *new_data*: This folder contains new generated split data (train, validation and test) from CORD-v2 dataset. These new datasets are generated by running the notebook **finetune_LayoutLMv3**

- ***finetune_LayoutLMv3.ipynb***: This notebook is used for:
    - Locally download CORD-v2 dataset
    - Make an EDA (exploratory data analysis)
    - Generate a new dataset from CORD-v2 dataset 
    - Prepare the data for training and testing the model
    - Finetune LayoutLMv3 model
    - Evaluate the trained model

- *model*: The model trained in the notebook **detect_total_amount.ipynb**


**Note**: In this project, we are finetuning a LayoutLMv3 model on receipts images for the total amount detection task. In order to use this model on receipts images contained in the *data* folder, an OCR step must first be performed to extract the text and boxes from the images (with easyOCR for example).

The data extracted from this OCR stage must also be prepared:
- Word positions in bounding box format [x0, y0, x1, y1]. 
- Integrate words, boxes and images into the processor